{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6399368-1316-4dcf-a5b9-835d22d9c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py\n",
    "\"\"\"Configuration parameters for the cattle segmentation project\"\"\"\n",
    "import os\n",
    "import torch\n",
    "\n",
    "class Config:\n",
    "    # Paths and dataset configuration\n",
    "    BASE_DIR = r'C:\\Users\\andrey\\.cache\\kagglehub\\datasets\\sadhliroomyprime\\cattle-weight-detection-model-dataset-12k\\versions\\3\\www.acmeai.tech Dataset - BMGF-LivestockWeight-CV\\Pixel\\B3'\n",
    "    SAVED_MODEL_PATH = 'best_cattle_segmentation_model_7.keras'\n",
    "    MODEL_TESTING_PATH = 'best_cattle_segmentation_model_6.keras'\n",
    "\n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 16\n",
    "    VAL_BATCH_SIZE = 16\n",
    "    NUM_WORKERS = 0  # Reduced from 8 to avoid potential threading issues\n",
    "    LEARNING_RATE = 0.002\n",
    "    NUM_EPOCHS = 25\n",
    "\n",
    "    # Model parameters\n",
    "    NUM_CLASSES = 3  # Updated to 3 classes: Sticker, Cattle, Background\n",
    "    IMAGE_SIZE = 512\n",
    "\n",
    "    # Device configuration\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    LIMIT = 350  # Set to the desired limit, e.g., 100 images for each\n",
    "\n",
    "\n",
    "\n",
    "# dataset.py\n",
    "\"\"\"Dataset classes and related utilities\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "\n",
    "def get_transforms(phase):\n",
    "    \"\"\"Get image transformations based on training/validation phase\"\"\"\n",
    "    if phase == 'train':\n",
    "        return A.Compose([\n",
    "            A.RandomResizedCrop(size=(512, 512), scale=(0.8, 1.0)),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.2),\n",
    "            A.Normalize()\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(height=512, width=512),\n",
    "            A.Normalize()\n",
    "        ])\n",
    "\n",
    "class CattleSegmentationDataset(Dataset):\n",
    "    \"\"\"Dataset for cattle segmentation with 3 classes\"\"\"\n",
    "    def __init__(self, img_paths, mask_paths, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.img_paths[idx]\n",
    "            mask_path = self.mask_paths[idx]\n",
    "            \n",
    "            # Read image and mask\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Could not read image at {img_path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            mask = cv2.imread(mask_path)\n",
    "            if mask is None:\n",
    "                raise ValueError(f\"Could not read mask at {mask_path}\")\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Convert RGB mask to class indices\n",
    "            sticker_mask = np.all(mask == [0, 117, 255], axis=-1).astype(np.uint8)  # Sticker (0, 117, 255)\n",
    "            cattle_mask = np.all(mask == [255, 30, 249], axis=-1).astype(np.uint8)  # Cattle (255, 30, 249)\n",
    "            background_mask = np.all(mask == [0, 255, 193], axis=-1).astype(np.uint8)  # Background (0, 255, 193)\n",
    "            \n",
    "            # Combine into a single mask where each pixel has a class index\n",
    "            final_mask = np.zeros(cattle_mask.shape, dtype=np.uint8)\n",
    "            final_mask[cattle_mask == 1] = 1  # Cattle class\n",
    "            final_mask[sticker_mask == 1] = 2  # Sticker class\n",
    "            final_mask[background_mask == 1] = 0  # Background class\n",
    "            \n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image, mask=final_mask)\n",
    "                image = augmented['image']\n",
    "                final_mask = augmented['mask']\n",
    "            \n",
    "            # Convert to tensors\n",
    "            image = torch.from_numpy(image.transpose(2, 0, 1)).float()  # Normalized in the transform\n",
    "            final_mask = torch.from_numpy(final_mask).long()\n",
    "            \n",
    "            return image, final_mask\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx} - {img_path}: {str(e)}\")\n",
    "            # Return a dummy sample to avoid crashing\n",
    "            dummy_image = torch.zeros((3, 512, 512), dtype=torch.float32)\n",
    "            dummy_mask = torch.zeros((512, 512), dtype=torch.long)\n",
    "            return dummy_image, dummy_mask\n",
    "\n",
    "\n",
    "def get_data_paths(base_dir):\n",
    "    \"\"\"Get all image and corresponding mask paths\"\"\"\n",
    "    img_paths = []\n",
    "    mask_paths = []\n",
    "    img_dir = os.path.join(base_dir, 'images')\n",
    "    mask_dir = os.path.join(base_dir, 'annotations')\n",
    "        \n",
    "    if os.path.exists(img_dir) and os.path.exists(mask_dir):\n",
    "        for img_name in os.listdir(img_dir):\n",
    "            if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(img_dir, img_name)\n",
    "                    \n",
    "                    # Construct mask name\n",
    "                mask_name = img_name + '___fuse.png'\n",
    "                mask_path = os.path.join(mask_dir, mask_name)\n",
    "                    \n",
    "                if os.path.exists(mask_path):\n",
    "                    img_paths.append(img_path)\n",
    "                    mask_paths.append(mask_path)\n",
    "                        \n",
    "    return img_paths, mask_paths\n",
    "\n",
    "                    \n",
    "# model.py\n",
    "\"\"\"Model definition and related functions\"\"\"\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# model.py\n",
    "\n",
    "def create_model(num_classes=3):\n",
    "    \"\"\"Create a UNet model with a ResNet18 backbone\"\"\"\n",
    "    try:\n",
    "        model = smp.Unet(\n",
    "            encoder_name=\"resnet18\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=3,\n",
    "            classes=num_classes,\n",
    "        )\n",
    "        print(\"Model created successfully\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# trainer.py\n",
    "\"\"\"Training functionality for the segmentation model\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# trainer.py\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_dataset, val_dataset, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = config.DEVICE\n",
    "        \n",
    "        # Move model to the configured device\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=config.NUM_WORKERS,\n",
    "            pin_memory=True  # Set to True with CUDA\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=config.VAL_BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=config.NUM_WORKERS,\n",
    "            pin_memory=True  # Set to True with CUDA\n",
    "        )\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {'train_loss': [], 'val_loss': [], 'val_iou': []}\n",
    "\n",
    "    def _validate_batch(self, images, masks):\n",
    "        \"\"\"Validate a single batch of data\"\"\"\n",
    "        # Check for NaNs in images and masks\n",
    "        if torch.isnan(images).any() or torch.isnan(masks).any():\n",
    "            print(\"Error: NaN values found in batch.\")\n",
    "            return False\n",
    "        \n",
    "        # Check if batch is empty\n",
    "        if images.shape[0] == 0:\n",
    "            print(\"Error: Empty batch.\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def train_one_epoch(self, epoch):\n",
    "        \"\"\"Train the model for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        print(f\"Starting epoch {epoch+1}/{self.config.NUM_EPOCHS}\")\n",
    "        train_pbar = tqdm(self.train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
    "        \n",
    "        for i, (images, masks) in enumerate(train_pbar):\n",
    "            # Validate batch\n",
    "            if not self._validate_batch(images, masks):\n",
    "                print(f\"Skipping invalid batch {i}\")\n",
    "                continue\n",
    "            \n",
    "            # Transfer to device\n",
    "            images = images.to(self.device)\n",
    "            masks = masks.to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, masks)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            current_loss = loss.item()\n",
    "            total_loss += current_loss\n",
    "            batch_count += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "        \n",
    "        # Calculate average loss\n",
    "        avg_loss = total_loss / max(batch_count, 1)\n",
    "        self.history['train_loss'].append(avg_loss)\n",
    "        \n",
    "        return avg_loss\n",
    "\n",
    "\n",
    "    \n",
    "    def validate(self, epoch):\n",
    "        \"\"\"Validate the model on the validation set\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_iou = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        val_pbar = tqdm(self.val_loader, desc=f\"Validation Epoch {epoch+1}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_pbar:\n",
    "                try:\n",
    "                    # Transfer to device\n",
    "                    images = images.to(self.device)\n",
    "                    masks = masks.to(self.device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs, masks)\n",
    "                    \n",
    "                    # Calculate IoU for cattle class (class index 1)\n",
    "                    pred_masks = torch.argmax(outputs, dim=1)\n",
    "                    intersection = torch.logical_and(pred_masks == 1, masks == 1).sum()\n",
    "                    union = torch.logical_or(pred_masks == 1, masks == 1).sum()\n",
    "                    iou = intersection / (union + 1e-10)\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    total_loss += loss.item()\n",
    "                    total_iou += iou.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    val_pbar.set_postfix(loss=f\"{loss.item():.4f}\", iou=f\"{iou.item():.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in validation batch: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_loss = total_loss / max(batch_count, 1)\n",
    "        avg_iou = total_iou / max(batch_count, 1)\n",
    "        \n",
    "        self.history['val_loss'].append(avg_loss)\n",
    "        self.history['val_iou'].append(avg_iou)\n",
    "        \n",
    "        return avg_loss, avg_iou\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train the model for the configured number of epochs\"\"\"\n",
    "        print(f\"Starting training for {self.config.NUM_EPOCHS} epochs\")\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(self.config.NUM_EPOCHS):\n",
    "            try:\n",
    "                # Train for one epoch\n",
    "                train_loss = self.train_one_epoch(epoch)\n",
    "                \n",
    "                # Validate\n",
    "                val_loss, val_iou = self.validate(epoch)\n",
    "                \n",
    "                # Print epoch summary\n",
    "                print(f\"Epoch {epoch+1}/{self.config.NUM_EPOCHS} - \"\n",
    "                      f\"Train Loss: {train_loss:.4f}, \"\n",
    "                      f\"Val Loss: {val_loss:.4f}, \"\n",
    "                      f\"Cattle IoU: {val_iou:.4f}\")\n",
    "                \n",
    "                # Save best model\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    torch.save(self.model.state_dict(), self.config.SAVED_MODEL_PATH)\n",
    "                    print(f\"Saved best model with validation loss: {val_loss:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in epoch {epoch+1}: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def plot_history(self):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history['train_loss'], label='Train Loss')\n",
    "        plt.plot(self.history['val_loss'], label='Val Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history['val_iou'], label='Cattle IoU')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('IoU')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.show()\n",
    "\n",
    "# prediction.py\n",
    "\"\"\"Functionality for making predictions with the trained model\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import os\n",
    "\n",
    "def predict_segmentation(image_path, model, device):\n",
    "    \"\"\"Predict segmentation mask for an image\"\"\"\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Store original dimensions for reference\n",
    "        original_height, original_width = image.shape[:2]\n",
    "\n",
    "        # Preprocess for model\n",
    "        transform = A.Compose([\n",
    "            A.Resize(height=512, width=512),\n",
    "            A.Normalize()\n",
    "        ])\n",
    "        \n",
    "        augmented = transform(image=image)\n",
    "        processed_image = augmented['image']\n",
    "        \n",
    "        # Convert to torch tensor and reorder the dimensions (channels, height, width)\n",
    "        image_tensor = torch.from_numpy(np.transpose(processed_image, (2, 0, 1))).float().unsqueeze(0)\n",
    "        \n",
    "        # Generate prediction\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image_tensor = image_tensor.to(device)\n",
    "            output = model(image_tensor)\n",
    "            pred_mask = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "        \n",
    "        return pred_mask, image\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "# prediction.py\n",
    "def visualize_segmentation(image_path, model, device):\n",
    "    \"\"\"Visualize segmentation results for a single image\"\"\"\n",
    "    pred_mask, original_img = predict_segmentation(image_path, model, device)\n",
    "    \n",
    "    if pred_mask is None:\n",
    "        print(f\"Failed to predict for {image_path}\")\n",
    "        return\n",
    "        \n",
    "    output_folder = './predictions'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    prediction_file_path = os.path.join(output_folder, f'segmentation_{os.path.basename(image_path)}.png')\n",
    "    \n",
    "    # Get dimensions of the original image\n",
    "    original_height, original_width = original_img.shape[:2]\n",
    "    \n",
    "    # Resize the prediction mask to match the original image dimensions\n",
    "    resized_mask = cv2.resize(pred_mask, (original_width, original_height), \n",
    "                             interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Create an overlay of the mask on the image\n",
    "    overlay = original_img.copy()\n",
    "    # Highlight different segments with different colors\n",
    "    overlay[resized_mask == 1] = [255, 30, 249]   # Cattle in pink\n",
    "    overlay[resized_mask == 2] = [0, 117, 255]    # Sticker in blue\n",
    "    overlay[resized_mask == 0] = [0, 255, 193]    # Background in green\n",
    "    \n",
    "    # Display the overlay image\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original_img)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(resized_mask, cmap='viridis')\n",
    "    plt.title('Segmentation Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title('Segmentation Overlay')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(prediction_file_path)\n",
    "    print(f\"Saved segmentation to {prediction_file_path}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# visualization.py\n",
    "\"\"\"Visualization utilities for the dataset and results\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_sample_masks(dataset, num_samples=3):\n",
    "    \"\"\"Visualize a few sample images and their masks from the dataset\"\"\"\n",
    "    fig, axs = plt.subplots(num_samples, 2, figsize=(12, 4*num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        try:\n",
    "            img, mask = dataset[i]\n",
    "            \n",
    "            # Convert tensors back to numpy for visualization\n",
    "            img = img.numpy().transpose(1, 2, 0)\n",
    "            img = (img - img.min()) / (img.max() - img.min())  # Normalize for display\n",
    "            mask = mask.numpy()\n",
    "            \n",
    "            # Display\n",
    "            axs[i, 0].imshow(img)\n",
    "            axs[i, 0].set_title('Original Image')\n",
    "            axs[i, 0].axis('off')\n",
    "            \n",
    "            axs[i, 1].imshow(mask, cmap='viridis')\n",
    "            axs[i, 1].set_title('Segmentation Mask')\n",
    "            axs[i, 1].axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing sample {i}: {str(e)}\")\n",
    "            # Leave this spot empty in the visualization\n",
    "            axs[i, 0].text(0.5, 0.5, f\"Error loading sample {i}\", \n",
    "                           ha='center', va='center')\n",
    "            axs[i, 0].axis('off')\n",
    "            axs[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_masks.png')\n",
    "    plt.show()\n",
    "\n",
    "# main.py\n",
    "\"\"\"Main execution script for the cattle segmentation project\"\"\"\n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import our modules\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config = Config()\n",
    "        print(f\"Using device: {config.DEVICE}\")\n",
    "\n",
    "        # Get data paths\n",
    "        img_paths, mask_paths = get_data_paths(config.BASE_DIR)\n",
    "        print(f\"Found {len(img_paths)} image-mask pairs\")\n",
    "\n",
    "        if len(img_paths) == 0:\n",
    "            raise ValueError(\"No images found. Check the dataset path.\")\n",
    "\n",
    "        # Limit the number of images if `LIMIT` is set\n",
    "        if config.LIMIT:\n",
    "            img_paths = img_paths[:config.LIMIT]\n",
    "            mask_paths = mask_paths[:config.LIMIT]\n",
    "            print(f\"Limiting to {config.LIMIT} images for training and validation\")\n",
    "\n",
    "        # Split data into training and validation sets\n",
    "        train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
    "            img_paths, mask_paths, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        print(f\"Training samples: {len(train_img_paths)}\")\n",
    "        print(f\"Validation samples: {len(val_img_paths)}\")\n",
    "\n",
    "        # Create datasets\n",
    "        train_dataset = CattleSegmentationDataset(\n",
    "            train_img_paths, train_mask_paths, transform=get_transforms('train')\n",
    "        )\n",
    "\n",
    "        val_dataset = CattleSegmentationDataset(\n",
    "            val_img_paths, val_mask_paths, transform=get_transforms('val')\n",
    "        )\n",
    "\n",
    "        # Visualize samples to verify dataset\n",
    "        print(\"Visualizing sample masks to verify dataset loading...\")\n",
    "        visualize_sample_masks(val_dataset)\n",
    "\n",
    "        # Create model\n",
    "        model = create_model(num_classes=config.NUM_CLASSES)\n",
    "\n",
    "        # Create trainer and train\n",
    "        trainer = Trainer(model, train_dataset, val_dataset, config)\n",
    "        trainer.train()\n",
    "\n",
    "        # Plot training history\n",
    "        trainer.plot_history()\n",
    "\n",
    "        # Load best model for prediction\n",
    "        best_model = create_model(num_classes=config.NUM_CLASSES)\n",
    "        best_model.load_state_dict(torch.load(config.MODEL_TESTING_PATH))\n",
    "        print(f\"Loaded model for segmentation prediction\")\n",
    "\n",
    "        # Test segmentation on validation samples\n",
    "        test_samples = val_img_paths[:10]  # Test on 10 samples\n",
    "        for img_path in test_samples:\n",
    "            print(f\"Segmenting image: {os.path.basename(img_path)}\")\n",
    "            visualize_segmentation(img_path, best_model, config.DEVICE)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Execute the main function if this is the main script\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

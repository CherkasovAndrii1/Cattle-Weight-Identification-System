{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79cadc7-5d09-4bdc-89fa-fa77b6f87716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications, callbacks\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.saving import load_model\n",
    "import time # Added for time measurement\n",
    "\n",
    "# --- DATA PATHS (Already specified by you) ---\n",
    "new_images_dir = r\"C:\\Users\\andrey\\.cache\\kagglehub\\datasets\\sadhliroomyprime\\cattle-weight-detection-model-dataset-12k\\versions\\3\\www.acmeai.tech Dataset - BMGF-LivestockWeight-CV\\Vector\\B3\\Side\\data\\images\"\n",
    "new_annotations_file = r\"C:\\Users\\andrey\\.cache\\kagglehub\\datasets\\sadhliroomyprime\\cattle-weight-detection-model-dataset-12k\\versions\\3\\www.acmeai.tech Dataset - BMGF-LivestockWeight-CV\\Vector\\B3\\Side\\data\\COCO_Side.json\"\n",
    "# ---------------------------------------------\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_LIMIT = 500 # Limit on the number of annotations to process\n",
    "TARGET_SIZE = (224, 224)\n",
    "NUM_KEYPOINTS = 9\n",
    "AUGMENT_DATA = True # Whether to perform data augmentation\n",
    "EPOCHS = 100 # Initial number of epochs\n",
    "BATCH_SIZE = 16\n",
    "# -------------------\n",
    "\n",
    "print(\"--- Script execution started ---\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Available GPUs: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Loading annotations from JSON\n",
    "print(f\"Loading annotations from: {new_annotations_file}\")\n",
    "try:\n",
    "    with open(new_annotations_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    print(\"Annotation file successfully loaded and parsed.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"!!! ERROR !!!: Could not find the annotation file: {new_annotations_file}\")\n",
    "    exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"!!! ERROR !!!: Could not parse the JSON file: {new_annotations_file}. Error: {e}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"!!! ERROR !!!: An unexpected error occurred while reading the annotation file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Checking the data structure\n",
    "print(\"Checking JSON structure...\")\n",
    "if not all(key in data for key in ['annotations', 'images', 'categories']):\n",
    "    print(\"!!! ERROR !!!: The JSON file has an incorrect structure. Expected keys 'annotations', 'images', 'categories'.\")\n",
    "    keys_found = list(data.keys())\n",
    "    print(f\"Keys found: {keys_found}\")\n",
    "    exit()\n",
    "print(\"JSON structure is correct.\")\n",
    "\n",
    "annotations = data['annotations']\n",
    "images_data = data['images'] # Renamed to avoid conflict with the module\n",
    "categories = data['categories']\n",
    "\n",
    "print(f\"Found {len(annotations)} annotations and {len(images_data)} image records in the JSON.\")\n",
    "\n",
    "# Function to load and augment images and keypoints\n",
    "def load_data(annotations, images_data, images_dir, target_size=TARGET_SIZE, num_keypoints=NUM_KEYPOINTS, augment=AUGMENT_DATA, limit=DATA_LIMIT):\n",
    "    print(f\"\\n--- Starting data loading (Limit: {limit} annotations) ---\")\n",
    "    start_time = time.time()\n",
    "    images_list = []\n",
    "    keypoints_list = []\n",
    "    image_info_list = []\n",
    "    processed_count = 0\n",
    "    skipped_annotations = 0\n",
    "    skipped_images = 0\n",
    "\n",
    "    # Create a dictionary for quick access to image information by ID\n",
    "    image_id_map = {img['id']: img for img in images_data}\n",
    "    print(f\"Created a map for {len(image_id_map)} images.\")\n",
    "\n",
    "    total_annotations_to_process = min(len(annotations), limit) if limit is not None else len(annotations)\n",
    "\n",
    "    for i, annotation in enumerate(annotations):\n",
    "        # --- CHANGE: Applying the limit ---\n",
    "        if limit is not None and processed_count >= limit:\n",
    "            print(f\"\\nReached the limit of {limit} successfully processed annotations. Stopping data loading.\")\n",
    "            break\n",
    "        # -----------------------------------\n",
    "\n",
    "        if (i + 1) % 50 == 0: # Logging progress\n",
    "            print(f\"  Processing annotation {i+1}/{len(annotations)} (Target: {processed_count}/{limit})...\")\n",
    "\n",
    "        image_id = annotation.get('image_id') # Safer way to get ID\n",
    "        if image_id is None:\n",
    "            print(f\"  Warning: Annotation {annotation.get('id', 'N/A')} is missing 'image_id'. Skipping.\")\n",
    "            skipped_annotations += 1\n",
    "            continue\n",
    "\n",
    "        # Check if image information exists\n",
    "        if image_id not in image_id_map:\n",
    "            print(f\"  Warning: Skipping annotation {annotation.get('id', 'N/A')} because no image with ID {image_id} was found.\")\n",
    "            skipped_annotations += 1\n",
    "            continue\n",
    "\n",
    "        image_info = image_id_map[image_id]\n",
    "        image_name = image_info.get('file_name')\n",
    "        if not image_name:\n",
    "            print(f\"  Warning: Image info for ID {image_id} is missing 'file_name'. Skipping annotation {annotation.get('id', 'N/A')}.\")\n",
    "            skipped_annotations += 1\n",
    "            continue\n",
    "\n",
    "        # Get original image dimensions\n",
    "        orig_width = image_info.get('width')\n",
    "        orig_height = image_info.get('height')\n",
    "        if not orig_width or not orig_height:\n",
    "            print(f\"  Warning: Image info for ID {image_id} ('{image_name}') is missing dimensions ('width' or 'height'). Skipping.\")\n",
    "            skipped_annotations += 1\n",
    "            continue\n",
    "\n",
    "        # Load the image\n",
    "        image_path = os.path.join(images_dir, image_name)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"  Warning: Image file not found: {image_path}. Skipping annotation {annotation.get('id', 'N/A')}.\")\n",
    "            skipped_annotations += 1\n",
    "            skipped_images += 1 # Count as a skipped image\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"  Warning: Failed to load image (cv2.imread returned None): {image_path}. Skipping.\")\n",
    "                skipped_annotations += 1\n",
    "                skipped_images += 1\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR reading image {image_path}: {e}. Skipping.\")\n",
    "            skipped_annotations += 1\n",
    "            skipped_images += 1\n",
    "            continue\n",
    "\n",
    "        # Resize the image\n",
    "        try:\n",
    "            image_resized = cv2.resize(image, target_size)\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR resizing image {image_path}: {e}. Skipping.\")\n",
    "            skipped_annotations += 1\n",
    "            continue\n",
    "\n",
    "        # Scale keypoint coordinates\n",
    "        scale_x = target_size[0] / orig_width\n",
    "        scale_y = target_size[1] / orig_height\n",
    "\n",
    "        keypoints_list_raw = annotation.get('keypoints')\n",
    "        if keypoints_list_raw is None:\n",
    "            print(f\"  Warning: Annotation {annotation.get('id', 'N/A')} is missing the 'keypoints' key. Skipping.\")\n",
    "            skipped_annotations += 1\n",
    "            continue\n",
    "\n",
    "        # --- Keypoint Processing ---\n",
    "        expected_kpt_len = num_keypoints * 3\n",
    "        if len(keypoints_list_raw) != expected_kpt_len:\n",
    "            print(f\"  Warning: Incorrect number of values ({len(keypoints_list_raw)}) in 'keypoints' for annotation {annotation['id']} (expected {expected_kpt_len}). Skipping.\")\n",
    "            skipped_annotations += 1\n",
    "            continue\n",
    "\n",
    "        keypoints_scaled = []\n",
    "        valid_keypoints = True\n",
    "        for ki in range(0, expected_kpt_len, 3):\n",
    "            try:\n",
    "                x_orig = float(keypoints_list_raw[ki])\n",
    "                y_orig = float(keypoints_list_raw[ki + 1])\n",
    "                # visibility = keypoints_list_raw[ki + 2] # Ignored\n",
    "            except (ValueError, TypeError) as e:\n",
    "                print(f\"  Warning: Invalid coordinate data ({keypoints_list_raw[ki]}, {keypoints_list_raw[ki+1]}) in annotation {annotation['id']}: {e}. Skipping annotation.\")\n",
    "                valid_keypoints = False\n",
    "                break # Stop processing keypoints for this annotation\n",
    "\n",
    "            if x_orig == 0 and y_orig == 0:\n",
    "                keypoints_scaled.append([0.0, 0.0])\n",
    "            else:\n",
    "                x = x_orig * scale_x\n",
    "                y = y_orig * scale_y\n",
    "                keypoints_scaled.append([x, y])\n",
    "\n",
    "        if not valid_keypoints:\n",
    "            skipped_annotations += 1\n",
    "            continue # Move to the next annotation\n",
    "\n",
    "        # Check if we got the correct number of points\n",
    "        if len(keypoints_scaled) != num_keypoints:\n",
    "            # This check is now less likely due to the previous array length check\n",
    "            print(f\"  Logic Error: After processing, got {len(keypoints_scaled)} points instead of {num_keypoints} for annotation {annotation['id']}. Skipping.\")\n",
    "            skipped_annotations += 1\n",
    "            continue\n",
    "        # -----------------------------\n",
    "\n",
    "        # --- If everything is okay, add the data and perform augmentation ---\n",
    "        current_image_normalized = image_resized / 255.0\n",
    "        current_keypoints_flat = np.array(keypoints_scaled).flatten()\n",
    "        current_info = {\n",
    "            'file_name': image_name,\n",
    "            'orig_width': orig_width,\n",
    "            'orig_height': orig_height,\n",
    "            'scale_x': scale_x,\n",
    "            'scale_y': scale_y,\n",
    "            'annotation_id': annotation.get('id', 'N/A') # Add annotation ID for debugging\n",
    "        }\n",
    "\n",
    "        images_list.append(current_image_normalized)\n",
    "        keypoints_list.append(current_keypoints_flat)\n",
    "        image_info_list.append(current_info)\n",
    "\n",
    "        # Augmentation\n",
    "        if augment:\n",
    "            # 1. Horizontal flip\n",
    "            try:\n",
    "                flipped_image = cv2.flip(image_resized, 1)\n",
    "                flipped_keypoints = []\n",
    "                for kp in keypoints_scaled:\n",
    "                    if kp[0] != 0 or kp[1] != 0:\n",
    "                        flipped_keypoints.append([target_size[0] - kp[0], kp[1]])\n",
    "                    else:\n",
    "                        flipped_keypoints.append([0.0, 0.0])\n",
    "                images_list.append(flipped_image / 255.0)\n",
    "                keypoints_list.append(np.array(flipped_keypoints).flatten())\n",
    "                image_info_list.append({**current_info, 'file_name': f\"flipped_{image_name}\"}) # Copy info\n",
    "            except Exception as e:\n",
    "                print(f\"  Error during augmentation (flip) for {image_name}: {e}\")\n",
    "\n",
    "            # 2. Brightness adjustment\n",
    "            try:\n",
    "                bright_image = np.clip(image_resized * np.random.uniform(0.8, 1.2), 0, 255).astype(np.uint8)\n",
    "                images_list.append(bright_image / 255.0)\n",
    "                keypoints_list.append(current_keypoints_flat) # Points don't change\n",
    "                image_info_list.append({**current_info, 'file_name': f\"bright_{image_name}\"})\n",
    "            except Exception as e:\n",
    "                print(f\"  Error during augmentation (bright) for {image_name}: {e}\")\n",
    "\n",
    "            # 3. Rotation\n",
    "            try:\n",
    "                angle = np.random.uniform(-15, 15)\n",
    "                center = (target_size[0] // 2, target_size[1] // 2)\n",
    "                M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "                rotated_image = cv2.warpAffine(image_resized, M, target_size)\n",
    "\n",
    "                rotated_keypoints = []\n",
    "                for kp in keypoints_scaled:\n",
    "                    if kp[0] != 0 or kp[1] != 0:\n",
    "                        point = np.array([[kp[0]], [kp[1]], [1]])\n",
    "                        rotated_point = M @ point\n",
    "                        rotated_keypoints.append([rotated_point[0, 0], rotated_point[1, 0]])\n",
    "                    else:\n",
    "                        rotated_keypoints.append([0.0, 0.0])\n",
    "                images_list.append(rotated_image / 255.0)\n",
    "                keypoints_list.append(np.array(rotated_keypoints).flatten())\n",
    "                image_info_list.append({**current_info, 'file_name': f\"rotated_{image_name}\"})\n",
    "            except Exception as e:\n",
    "                print(f\"  Error during augmentation (rotate) for {image_name}: {e}\")\n",
    "\n",
    "        processed_count += 1 # Increment the counter ONLY AFTER successfully processing ONE annotation\n",
    "\n",
    "    # --- End of loading loop ---\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n--- Data loading finished in {end_time - start_time:.2f} sec ---\")\n",
    "    print(f\"Successfully processed annotations: {processed_count}\")\n",
    "    print(f\"Skipped annotations due to errors/filters: {skipped_annotations}\")\n",
    "    print(f\"Skipped images due to loading/path errors: {skipped_images}\")\n",
    "    print(f\"Total examples (with augmentation): {len(images_list)}\")\n",
    "\n",
    "    if not images_list:\n",
    "        print(\"!!! ERROR !!!: Image list is empty after data loading!\")\n",
    "        return None, None, None # Return None to indicate an error\n",
    "\n",
    "    return np.array(images_list), np.array(keypoints_list), image_info_list\n",
    "\n",
    "# --- LOADING DATA WITH A LIMIT ---\n",
    "X, y, image_info_list = load_data(annotations, images_data, new_images_dir)\n",
    "\n",
    "# --- POST-LOADING CHECK ---\n",
    "if X is None or X.shape[0] == 0:\n",
    "    print(\"\\n!!! CRITICAL ERROR !!!: Failed to load data. Further execution is not possible.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nShape of loaded images (X):\", X.shape)\n",
    "print(\"Shape of loaded keypoints (y):\", y.shape)\n",
    "print(f\"Number of examples for training (with augmentation): {X.shape[0]}\")\n",
    "\n",
    "# --- DATA SPLITTING ---\n",
    "print(\"\\nSplitting data into training and validation sets...\")\n",
    "try:\n",
    "    X_train, X_val, y_train, y_val, info_train, info_val = train_test_split(\n",
    "        X, y, image_info_list, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"Training set: {X_train.shape[0]} examples\")\n",
    "    print(f\"Validation set: {X_val.shape[0]} examples\")\n",
    "except ValueError as e:\n",
    "    print(f\"\\n!!! ERROR during data splitting: {e}\")\n",
    "    print(\"Perhaps too little data was loaded to split. Check DATA_LIMIT.\")\n",
    "    exit()\n",
    "\n",
    "# --- MODEL CREATION ---\n",
    "print(\"\\nCreating the model...\")\n",
    "def create_improved_model(img_height, img_width, num_keypoints):\n",
    "    print(f\"  Creating EfficientNetB3 base model (input: {img_height}x{img_width}x3)\")\n",
    "    base_model = applications.EfficientNetB3(\n",
    "        input_shape=(img_height, img_width, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    print(\"  Base model created.\")\n",
    "\n",
    "    trainable_layers = 30\n",
    "    print(f\"  Freezing base model layers, except for the last {trainable_layers} (and BN)\")\n",
    "    for layer in base_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-trainable_layers:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "    print(\"  Layers frozen/unfrozen.\")\n",
    "\n",
    "    inputs = layers.Input(shape=(img_height, img_width, 3))\n",
    "    x = inputs # Assuming normalization in load_data\n",
    "\n",
    "    print(\"  Building the custom model 'head'...\")\n",
    "    x = base_model(x, training=False) # Important: training=False for BN in frozen layers\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_keypoints * 2, activation='linear', name='keypoints_output')(x)\n",
    "    print(f\"  Output layer created: {num_keypoints * 2} neurons.\")\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    print(\"Model successfully created.\")\n",
    "    return model\n",
    "\n",
    "model = create_improved_model(TARGET_SIZE[0], TARGET_SIZE[1], NUM_KEYPOINTS)\n",
    "\n",
    "# --- OPTIMIZER AND LOSS FUNCTION ---\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=max(1, (X_train.shape[0] // BATCH_SIZE) * 5), # Adapt decay_steps\n",
    "    decay_rate=0.9, staircase=True\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "# --- MODEL COMPILATION ---\n",
    "print(\"\\nCompiling the model...\")\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse',  # or another built-in loss like 'mae'\n",
    "    metrics=['mae']\n",
    ")\n",
    "print(\"Model compiled.\")\n",
    "model.summary()\n",
    "\n",
    "# --- CALLBACKS ---\n",
    "print(\"\\nSetting up callbacks...\")\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=15, verbose=1, restore_best_weights=True\n",
    ")\n",
    "# reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss', factor=0.2, patience=5, verbose=1, min_lr=1e-6\n",
    "# )\n",
    "checkpoint_path = 'best_keypoints_model_9pts_limited.keras' # Change the name for the limited version\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1\n",
    ")\n",
    "print(f\"Callbacks configured. The best model will be saved to '{checkpoint_path}'\")\n",
    "\n",
    "# --- MODEL TRAINING ---\n",
    "def train_model_func(X_train, y_train, X_val, y_val, model, epochs=EPOCHS, batch_size=BATCH_SIZE):\n",
    "    print(f\"\\n--- Starting model training ({epochs} epochs, batch_size={batch_size}) ---\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"--- Training finished ---\")\n",
    "    return history\n",
    "\n",
    "# Uncomment to train:\n",
    "# history = train_model_func(X_train, y_train, X_val, y_val, model)\n",
    "# Instead, for testing without a long training session, you can try to load a pre-trained model,\n",
    "# or just skip training if `checkpoint_path` already exists.\n",
    "# For this example, we'll leave the training commented out. If the model file doesn't exist, the script will notify you.\n",
    "history = None # Initialize so that plot_history doesn't cause an error if training is skipped\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Found an existing model file '{checkpoint_path}'. Training will be skipped unless uncommented above.\")\n",
    "else:\n",
    "    print(f\"Model file '{checkpoint_path}' not found. If needed, uncomment the training block.\")\n",
    "    # If you want to train when the model is not found:\n",
    "    # print(\"Starting training because the model was not found...\")\n",
    "    # history = train_model_func(X_train, y_train, X_val, y_val, model)\n",
    "\n",
    "\n",
    "# --- TRAINING VISUALIZATION ---\n",
    "def plot_history(history):\n",
    "    if not history or not history.history:\n",
    "        print(\"No history data to visualize (perhaps training was skipped or the model was loaded).\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nVisualizing the training process...\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    try:\n",
    "        # Loss plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Loss (Training)')\n",
    "        plt.plot(history.history['val_loss'], label='Loss (Validation)')\n",
    "        plt.title('Loss Function Dynamics')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # MAE metric plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['mae'], label='MAE (Training)')\n",
    "        plt.plot(history.history['val_mae'], label='MAE (Validation)')\n",
    "        plt.title('Mean Absolute Error Dynamics')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"Training plots displayed.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error during visualization: missing key in training history: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while plotting graphs: {e}\")\n",
    "\n",
    "if history: # Call only if training occurred\n",
    "    plot_history(history)\n",
    "\n",
    "# --- FUNCTIONS FOR PREDICTION AND VISUALIZATION (remain unchanged) ---\n",
    "def rescale_keypoints(scaled_keypoints_flat, orig_width, orig_height, target_size=TARGET_SIZE):\n",
    "    scale_x = orig_width / target_size[0]\n",
    "    scale_y = orig_height / target_size[1]\n",
    "    scaled_keypoints = scaled_keypoints_flat.reshape(-1, 2)\n",
    "    rescaled_keypoints = []\n",
    "    for kp in scaled_keypoints:\n",
    "        x = kp[0] * scale_x\n",
    "        y = kp[1] * scale_y\n",
    "        rescaled_keypoints.append([x, y])\n",
    "    return np.array(rescaled_keypoints)\n",
    "\n",
    "def visualize_keypoints(image_path, predicted_keypoints_original, title=\"Predicted Keypoints\"):\n",
    "    print(f\"\\nVisualizing result for: {image_path}\")\n",
    "    print(f\"  Predicted keypoints (original scale): {predicted_keypoints_original}\")\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"  Error: Failed to load image for visualization: {image_path}\")\n",
    "        return\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    orig_height, orig_width = image.shape[:2]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_rgb)\n",
    "\n",
    "    # Copy image_rgb for drawing so as not to change the original shown by imshow\n",
    "    image_to_draw_on = image_rgb.copy()\n",
    "\n",
    "    for i, point in enumerate(predicted_keypoints_original):\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        # Draw only if the point is within the image boundaries\n",
    "        if 0 <= x < orig_width and 0 <= y < orig_height:\n",
    "            color_map = plt.get_cmap(\"tab10\") # Use a color palette\n",
    "            # Convert color from RGBA (0-1) to RGB for plt\n",
    "            color_for_plt = color_map(i / NUM_KEYPOINTS) # Normalize index for the palette\n",
    "\n",
    "            # Draw on the copy of the image\n",
    "            # We use cv2.circle, but on image_to_draw_on\n",
    "            # Convert plt color (R,G,B,A) to (B,G,R) for cv2, but here we work with RGB\n",
    "            cv_color = tuple(int(c * 255) for c in color_for_plt[:3]) # Take only RGB, ignore alpha\n",
    "\n",
    "            cv2.circle(image_to_draw_on, (x, y), radius=max(5, int(min(orig_width, orig_height)*0.01)), color=cv_color, thickness=-1) # Filled circle\n",
    "            cv2.circle(image_to_draw_on, (x, y), radius=max(7, int(min(orig_width, orig_height)*0.012)), color=(255,255,255), thickness=2) # White outline\n",
    "\n",
    "    plt.imshow(image_to_draw_on) # Show the image with drawn points\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    save_path = './predicted_keypoints_output_limited.png'\n",
    "    try:\n",
    "        # Save the image with drawn points, converting from RGB to BGR for cv2.imwrite\n",
    "        image_to_save_bgr = cv2.cvtColor(image_to_draw_on, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(save_path, image_to_save_bgr)\n",
    "        print(f\"  Image with keypoints saved to: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to save the image: {e}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def predict_keypoints(image_path, model, target_size=TARGET_SIZE):\n",
    "    print(f\"\\nPrediction for image: {image_path}\")\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"  Error: Failed to load image for prediction: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    orig_height, orig_width = image.shape[:2]\n",
    "    print(f\"  Original size: {orig_width}x{orig_height}\")\n",
    "\n",
    "    try:\n",
    "        image_resized = cv2.resize(image, target_size)\n",
    "        image_input = image_resized / 255.0\n",
    "        image_input = np.expand_dims(image_input, axis=0)\n",
    "        print(f\"  Input data shape for model: {image_input.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error preparing image for prediction: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        start_pred_time = time.time()\n",
    "        keypoints_pred_scaled_flat = model.predict(image_input)\n",
    "        end_pred_time = time.time()\n",
    "        print(f\"  Prediction executed in {end_pred_time - start_pred_time:.4f} sec.\")\n",
    "        print(f\"  Model output shape: {keypoints_pred_scaled_flat.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during model.predict execution: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        keypoints_original = rescale_keypoints(keypoints_pred_scaled_flat[0], orig_width, orig_height, target_size)\n",
    "        print(f\"  Predicted keypoints shape (original scale): {keypoints_original.shape}\")\n",
    "        # print(f\"  Predicted keypoints: {keypoints_original}\") # Commented out, as it's printed in visualize_keypoints\n",
    "        return keypoints_original\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during keypoint rescaling: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- MODEL USAGE ---\n",
    "print(\"\\n--- Loading and testing the best model ---\")\n",
    "best_model = None\n",
    "if os.path.exists(checkpoint_path):\n",
    "    try:\n",
    "        print(f\"Loading model from: {checkpoint_path}\")\n",
    "        best_model = load_model(checkpoint_path)\n",
    "        print(\"Model successfully loaded.\")\n",
    "\n",
    "        # --- CHANGE THE PATH to the test image ---\n",
    "        # Specify the path to ONE of your NEW images for testing\n",
    "        # Important: this image MUST be among those in images_dir\n",
    "        # Example, REPLACE WITH A REAL FILE!\n",
    "        # test_image_filename = \"9_s_181_F.jpg\" # Example\n",
    "        # Let's try to take the first image from the validation set, if it exists\n",
    "        test_image_path = None\n",
    "        if 'info_val' in locals() and info_val and len(info_val) > 0:\n",
    "            test_image_filename = info_val[0]['file_name']\n",
    "            test_image_path = os.path.join(new_images_dir, test_image_filename)\n",
    "            print(f\"Selected test image from validation set: {test_image_filename}\")\n",
    "        else: # If the validation set does not exist or is empty, use a fallback\n",
    "            default_test_image = \"9_s_181_F.jpg\" # REPLACE IF THIS FILE DOESN'T EXIST\n",
    "            test_image_path = os.path.join(new_images_dir, default_test_image)\n",
    "            print(f\"Validation set is empty or unavailable. Using default test image: {default_test_image}\")\n",
    "            print(f\"!!! ATTENTION: Make sure the file '{default_test_image}' exists in '{new_images_dir}' !!!\")\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        print(f\"Path to the test image: {test_image_path}\")\n",
    "\n",
    "        if test_image_path and os.path.exists(test_image_path):\n",
    "            predicted_keypoints = predict_keypoints(test_image_path, best_model)\n",
    "            if predicted_keypoints is not None:\n",
    "                visualize_keypoints(test_image_path, predicted_keypoints)\n",
    "        else:\n",
    "            print(f\"!!! ERROR: Test image NOT FOUND at path: {test_image_path}\")\n",
    "            print(\"!!! Check if the file exists and the filename is correct, or if the validation set is not empty.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! ERROR while loading or using the model: {e}\")\n",
    "        print(f\"!!! Make sure the file '{checkpoint_path}' exists, is not corrupted, and that training ran at least partially.\")\n",
    "else:\n",
    "    print(f\"WARNING: The best model file '{checkpoint_path}' was not found. Testing is not possible.\")\n",
    "\n",
    "\n",
    "# --- MODEL EVALUATION (PCK) ---\n",
    "# Updated calculate_pck function (info_val removed)\n",
    "def calculate_pck(model, X_val, y_val, threshold_factor=0.2, target_size=TARGET_SIZE, num_keypoints=NUM_KEYPOINTS):\n",
    "    if X_val is None or X_val.shape[0] == 0:\n",
    "        print(\"Cannot calculate PCK: validation set is empty.\")\n",
    "        return 0.0\n",
    "\n",
    "    correct_keypoints = 0\n",
    "    total_visible_keypoints = 0\n",
    "\n",
    "    # Changed: The message about PCK calculation will be made by the calling function (plot_pck_curve) or once\n",
    "    # print(f\"\\n--- Calculating PCK@{threshold_factor} on the validation set ({X_val.shape[0]} examples)... ---\")\n",
    "    try:\n",
    "        predictions_scaled_flat = model.predict(X_val, verbose=0) # verbose=0 to reduce output in the loop\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during prediction on the validation set: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "    normalizer = np.sqrt(target_size[0]**2 + target_size[1]**2) * threshold_factor\n",
    "\n",
    "    for i in range(len(X_val)):\n",
    "        try:\n",
    "            pred_keypoints_scaled = predictions_scaled_flat[i].reshape(num_keypoints, 2)\n",
    "            gt_keypoints_scaled = y_val[i].reshape(num_keypoints, 2)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error on reshape during PCK calculation for example {i}: {e}\")\n",
    "            continue # Skip this example\n",
    "\n",
    "        for j in range(num_keypoints):\n",
    "            # A keypoint is considered visible if its ground truth coordinates are not (0,0)\n",
    "            # (this is an assumption used during data loading for missing points)\n",
    "            if gt_keypoints_scaled[j][0] != 0 or gt_keypoints_scaled[j][1] != 0:\n",
    "                total_visible_keypoints += 1\n",
    "                try:\n",
    "                    error = np.sqrt(np.sum((pred_keypoints_scaled[j] - gt_keypoints_scaled[j])**2))\n",
    "                    if error < normalizer:\n",
    "                        correct_keypoints += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error calculating error/pck for point {j} of example {i}: {e}\")\n",
    "\n",
    "    if total_visible_keypoints == 0:\n",
    "        # print(\"WARNING: No visible keypoints found in the validation set to calculate PCK.\")\n",
    "        return 0.0 # Return 0.0 if there are no visible points\n",
    "\n",
    "    pck = correct_keypoints / total_visible_keypoints\n",
    "    # Changed: The output will be made by the calling function\n",
    "    # print(f\"  Number of visible keypoints in the validation set: {total_visible_keypoints}\")\n",
    "    # print(f\"  Number of correctly detected keypoints: {correct_keypoints}\")\n",
    "    # print(f\"  PCK@{threshold_factor}: {pck:.4f}\")\n",
    "    return pck\n",
    "\n",
    "# New function to visualize the PCK curve\n",
    "def plot_pck_curve(model, X_val, y_val, target_size=TARGET_SIZE, num_keypoints=NUM_KEYPOINTS):\n",
    "    if X_val is None or X_val.shape[0] == 0:\n",
    "        print(\"Cannot plot PCK curve: validation set is empty.\")\n",
    "        return\n",
    "\n",
    "    thresholds = np.linspace(0.01, 0.5, num=20) # Range of thresholds\n",
    "    pck_values = []\n",
    "\n",
    "    print(f\"\\n--- Calculating PCK for various thresholds to plot the curve (on {X_val.shape[0]} examples)... ---\")\n",
    "    for thresh in thresholds:\n",
    "        print(f\"  Calculating PCK for threshold: {thresh:.3f}\")\n",
    "        current_pck = calculate_pck(model, X_val, y_val, threshold_factor=thresh, target_size=target_size, num_keypoints=num_keypoints)\n",
    "        pck_values.append(current_pck)\n",
    "        print(f\"  PCK@{thresh:.3f}: {current_pck:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, pck_values, marker='o', linestyle='-')\n",
    "    plt.title('PCK Curve (Percentage of Correct Keypoints)')\n",
    "    plt.xlabel(f'Threshold (fraction of the diagonal of the target size {target_size})')\n",
    "    plt.ylabel('PCK@threshold')\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 1.05) # PCK is in the range [0, 1]\n",
    "    # Configure the number of ticks on the X-axis for better readability\n",
    "    num_xticks = 10\n",
    "    xtick_indices = np.linspace(0, len(thresholds) - 1, num_xticks, dtype=int)\n",
    "    plt.xticks(thresholds[xtick_indices], [f\"{thresholds[i]:.2f}\" for i in xtick_indices], rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"PCK curve displayed.\")\n",
    "\n",
    "\n",
    "if best_model is not None and X_val is not None and X_val.shape[0] > 0:\n",
    "    print(\"\\nEvaluating the loaded model (single threshold)...\")\n",
    "    # Updated call to calculate_pck\n",
    "    default_threshold = 0.2\n",
    "    pck_score = calculate_pck(best_model, X_val, y_val, threshold_factor=default_threshold)\n",
    "    print(f\"--- PCK Result for threshold {default_threshold} ---\")\n",
    "    print(f\"  PCK@{default_threshold}: {pck_score:.4f} (Calculated on {X_val.shape[0]} validation examples)\")\n",
    "\n",
    "    # Call the new function to visualize the PCK curve\n",
    "    plot_pck_curve(best_model, X_val, y_val)\n",
    "\n",
    "else:\n",
    "    if best_model is None:\n",
    "        print(\"\\nCannot evaluate model and plot PCK curve: model not loaded.\")\n",
    "    if X_val is None or X_val.shape[0] == 0:\n",
    "        print(\"\\nCannot evaluate model and plot PCK curve: validation set is empty or was not created.\")\n",
    "\n",
    "\n",
    "# --- FINE-TUNING - optional ---\n",
    "# (The fine_tune_model function code would go here, as in the previous response)\n",
    "# ... (fine_tune_model function code) ...\n",
    "\n",
    "# --- COMPLETION ---\n",
    "print(\"\\n--- Script execution finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
